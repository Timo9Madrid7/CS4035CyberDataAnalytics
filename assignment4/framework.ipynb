{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\"\"\"\n",
    "Python module for performing adversarial training for malware detection\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from utils.utils import load_parameters, stack_tensors\n",
    "from utils.script_functions import merge_metrics\n",
    "from datasets.datasets import load_data\n",
    "from inner_maximizers.inner_maximizers import inner_maximizer\n",
    "from nets.ff_classifier import build_ff_classifier\n",
    "from blindspot_coverage.covering_number import CoveringNumber\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main(config_file=\"parameters.ini\"):\n",
    "    # Step 1. Load configuration\n",
    "    parameters = load_parameters(config_file)\n",
    "    is_cuda = eval(parameters[\"general\"][\"is_cuda\"])\n",
    "    if is_cuda:\n",
    "        # gotcha On some platforms, modifying os.environ will not modify the system environment\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = parameters[\"general\"][\"gpu_device\"]\n",
    "\n",
    "    assertion_message = \"Set this flag off to train models.\"\n",
    "    assert eval(parameters['dataset']['generate_feature_vector_files']) is False, assertion_message\n",
    "\n",
    "    log_interval = int(parameters[\"general\"][\"log_interval\"])\n",
    "    num_epochs = int(parameters[\"hyperparam\"][\"ff_num_epochs\"])\n",
    "    is_synthetic_dataset = eval(parameters[\"general\"][\"is_synthetic_dataset\"])\n",
    "\n",
    "    training_method = parameters[\"general\"][\"training_method\"]\n",
    "    evasion_method = parameters[\"general\"][\"evasion_method\"]\n",
    "    experiment_suffix = parameters[\"general\"][\"experiment_suffix\"]\n",
    "    experiment_name = \"[training:%s|evasion:%s]_%s\" % (training_method, evasion_method,\n",
    "                                                       experiment_suffix)\n",
    "\n",
    "    adv_example_filepath = parameters[\"challenge\"][\"adv_examples_path\"]\n",
    "\n",
    "    print(\"Training Method:%s, Evasion Method:%s\" % (training_method, evasion_method))\n",
    "\n",
    "    seed_val = int(parameters[\"general\"][\"seed\"])\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "\n",
    "    evasion_iterations = int(parameters['hyperparam']['evasion_iterations'])\n",
    "\n",
    "    save_every_epoch = eval(parameters['general']['save_every_epoch'])\n",
    "\n",
    "    #train_model_from_scratch = eval(parameters['general']['train_model_from_scratch'])\n",
    "    load_model_weights = eval(parameters['general']['load_model_weights'])\n",
    "    model_weights_path = parameters['general']['model_weights_path']\n",
    "\n",
    "    # Step 2. Load training and test data\n",
    "    train_dataloader_dict, valid_dataloader_dict, test_dataloader_dict, num_features = load_data(\n",
    "        parameters)\n",
    "\n",
    "    # set the bscn metric\n",
    "    num_samples = len(train_dataloader_dict[\"malicious\"].dataset)\n",
    "    bscn = CoveringNumber(num_samples, num_epochs * num_samples,\n",
    "                          train_dataloader_dict[\"malicious\"].batch_size)\n",
    "\n",
    "    if load_model_weights:\n",
    "        print(\"Loading Model Weights From: {path}\".format(path=model_weights_path))\n",
    "        model = torch.load(model_weights_path)\n",
    "\n",
    "    else:\n",
    "        # Step 3. Construct neural net (N) - this can be replaced with any model of interest\n",
    "        model = build_ff_classifier(\n",
    "            input_size=num_features,\n",
    "            hidden_1_size=int(parameters[\"hyperparam\"][\"ff_h1\"]),\n",
    "            hidden_2_size=int(parameters[\"hyperparam\"][\"ff_h2\"]),\n",
    "            hidden_3_size=int(parameters[\"hyperparam\"][\"ff_h3\"]))\n",
    "    # gpu related setups\n",
    "    if is_cuda:\n",
    "        torch.cuda.manual_seed(int(parameters[\"general\"][\"seed\"]))\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Step 4. Define loss function and optimizer  for training (back propagation block in Fig 2.)\n",
    "    loss_fct = nn.NLLLoss(reduce=False)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=float(parameters[\"hyperparam\"][\"ff_learning_rate\"]))\n",
    "\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        total_correct = 0.\n",
    "        total_loss = 0.\n",
    "        total = 0.\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if is_synthetic_dataset:\n",
    "            # since generation of synthetic data set is random, we'd like them to be the same over epochs\n",
    "            torch.manual_seed(seed_val)\n",
    "            random.seed(seed_val)\n",
    "\n",
    "        for batch_idx, ((bon_x, bon_y), (mal_x, mal_y)) in enumerate(\n",
    "                zip(train_dataloader_dict[\"benign\"], train_dataloader_dict[\"malicious\"])):\n",
    "            # Check for adversarial learning\n",
    "            mal_x = inner_maximizer(\n",
    "                mal_x, mal_y, model, loss_fct, iterations=evasion_iterations, method=training_method)\n",
    "\n",
    "            # stack input\n",
    "            if is_cuda:\n",
    "                x = Variable(stack_tensors(bon_x, mal_x).cuda())\n",
    "                y = Variable(stack_tensors(bon_y, mal_y).cuda())\n",
    "            else:\n",
    "                x = Variable(stack_tensors(bon_x, mal_x))\n",
    "                y = Variable(stack_tensors(bon_y, mal_y))\n",
    "\n",
    "            # forward pass\n",
    "            y_model = model(x)\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fct(y_model, y).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # predict pass\n",
    "            _, predicted = torch.topk(y_model, k=1)\n",
    "            correct = predicted.data.eq(y.data.view_as(predicted.data)).cpu().sum()\n",
    "\n",
    "            # metrics\n",
    "            total_loss += loss.data[0] * len(y)\n",
    "            total_correct += correct\n",
    "            total += len(y)\n",
    "\n",
    "            bscn.update_numerator_batch(batch_idx, mal_x)\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(\"Time Taken:\", time.time() - current_time)\n",
    "                current_time = time.time()\n",
    "                print(\n",
    "                    \"Train Epoch ({}) | Batch ({}) | [{}/{} ({:.0f}%)]\\tBatch Loss: {:.6f}\\tBatch Accuracy: {:.1f}%\\t BSCN: {:.12f}\".\n",
    "                        format(epoch, batch_idx, batch_idx * len(x),\n",
    "                               len(train_dataloader_dict[\"malicious\"].dataset) +\n",
    "                               len(train_dataloader_dict[\"benign\"].dataset),\n",
    "                               100. * batch_idx / len(train_dataloader_dict[\"benign\"]), loss.data[0],\n",
    "                               100. * correct / len(y), bscn.ratio()))\n",
    "\n",
    "        model_filename = \"{name}_epoch_{e}\".format(name=experiment_name, e=epoch)\n",
    "\n",
    "        if save_every_epoch:\n",
    "            torch.save(model, os.path.join(\"model_weights\", model_filename))\n",
    "\n",
    "    def check_one_category(category=\"benign\", dset_type='test', is_evade=False,\n",
    "                           evade_method='dfgsm_k'):\n",
    "        \"\"\"\n",
    "        test the model in terms of loss and accuracy on category, this function also allows to perform perturbation\n",
    "        with respect to loss to evade\n",
    "        :param category: benign or malicious dataset\n",
    "        :param dset_type: 'val', 'test', or 'train' dataset\n",
    "        :param is_evade: to perform evasion or not\n",
    "        :param evade_method: evasion method (we can use on of the inner maximier methods), it is only relevant if is_evade\n",
    "          is True\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "        evasion_mode = \"\"\n",
    "        \n",
    "        tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "        if is_synthetic_dataset:\n",
    "            # since generation of synthetic data set is random, we'd like them to be the same over epochs\n",
    "            torch.manual_seed(seed_val)\n",
    "            random.seed(seed_val)\n",
    "\n",
    "        if dset_type == 'train':\n",
    "            dataloader = train_dataloader_dict[category]\n",
    "        elif dset_type == 'val':\n",
    "            dataloader = valid_dataloader_dict[category]\n",
    "        elif dset_type == 'test':\n",
    "            dataloader = test_dataloader_dict[category]\n",
    "        else:\n",
    "            raise Exception(\"Invalid Dataset type\")\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            #\n",
    "            if is_evade:\n",
    "                x = inner_maximizer(\n",
    "                    x, y, model, loss_fct, iterations=evasion_iterations, method=evade_method)\n",
    "                evasion_mode = \"(evasion using %s)\" % evade_method\n",
    "            # stack input\n",
    "            if is_cuda:\n",
    "                x = Variable(x.cuda())\n",
    "                y = Variable(y.cuda())\n",
    "            else:\n",
    "                x = Variable(x)\n",
    "                y = Variable(y)\n",
    "\n",
    "            # forward pass\n",
    "            y_model = model(x)\n",
    "\n",
    "            # loss pass\n",
    "            loss = loss_fct(y_model, y).mean()\n",
    "\n",
    "            # predict pass\n",
    "            _, predicted = torch.topk(y_model, k=1)\n",
    "            correct = predicted.data.eq(y.data.view_as(predicted.data)).cpu().sum()\n",
    "            \n",
    "            pred_label = predicted.data.cpu().numpy()[0][0]\n",
    "            true_label = y.data.view_as(predicted.data).cpu().numpy()[0]\n",
    "            \n",
    "            if (pred_label == 1 and true_label == 1):\n",
    "                tp += 1\n",
    "            elif (pred_label == 0 and true_label == 0):\n",
    "                tn += 1\n",
    "            elif (true_label == 1 and pred_label == 0):\n",
    "                fn += 1\n",
    "            elif (true_label == 0 and pred_label == 1):\n",
    "                fp += 1\n",
    "\n",
    "            # metrics\n",
    "            total_loss += loss.data[0] * len(y)\n",
    "            total_correct += correct\n",
    "            total += len(y)\n",
    "\n",
    "        print(\"TP:\",tp, \"FN\",fn, \"FP\",fp, \"TN\",tn, \"F1\",2*tp/(2*tp+fp+fn))\n",
    "        print(\"{} set for {} {}: Average Loss: {:.4f}, Accuracy: {:.2f}%\".format(\n",
    "            dset_type, category, evasion_mode, total_loss / total,\n",
    "                                               total_correct * 100. / total))\n",
    "\n",
    "        return total_loss, total_correct, total\n",
    "\n",
    "    def test(epoch, dset_type='test'):\n",
    "        \"\"\"\n",
    "        Function to be used for both testing and validation\n",
    "        :param epoch: current epoch\n",
    "        :param dset_type: 'train', 'test' , or 'val'\n",
    "        :return: average total loss, dictionary of the metrics for both bon and mal samples\n",
    "        \"\"\"\n",
    "        # test for accuracy and loss\n",
    "        bon_total_loss, bon_total_correct, bon_total = check_one_category(\n",
    "            category=\"benign\", is_evade=False, dset_type=dset_type)\n",
    "        mal_total_loss, mal_total_correct, mal_total = check_one_category(\n",
    "            category=\"malicious\", is_evade=False, dset_type=dset_type)\n",
    "\n",
    "        # test for evasion on malicious sample\n",
    "        evade_mal_total_loss, evade_mal_total_correct, evade_mal_total = check_one_category(\n",
    "            category=\"malicious\", is_evade=True, evade_method=evasion_method, dset_type=dset_type)\n",
    "\n",
    "        total_loss = bon_total_loss + mal_total_loss\n",
    "        total_correct = bon_total_correct + mal_total_correct\n",
    "        total = bon_total + mal_total\n",
    "\n",
    "        print(\"{} set overall: Average Loss: {:.4f}, Accuracy: {:.2f}%\".format(\n",
    "            dset_type, total_loss / total, total_correct * 100. / total))\n",
    "\n",
    "        metrics = {\n",
    "            \"bscn_num_pts\": bscn.num_pts(),\n",
    "            \"bscn_exp_pts\": bscn.exp_num_pts(),\n",
    "            \"mal\": {\n",
    "                \"total_loss\": mal_total_loss,\n",
    "                \"total_correct\": mal_total_correct,\n",
    "                \"total\": mal_total,\n",
    "                \"evasion\": {\n",
    "                    \"total_loss\": evade_mal_total_loss,\n",
    "                    \"total_correct\": evade_mal_total_correct,\n",
    "                    \"total\": evade_mal_total\n",
    "                }\n",
    "            },\n",
    "            \"bon\": {\n",
    "                \"total_loss\": bon_total_loss,\n",
    "                \"total_correct\": bon_total_correct,\n",
    "                \"total\": bon_total\n",
    "            }\n",
    "        }\n",
    "        print(metrics)\n",
    "\n",
    "        return (bon_total_loss + max(mal_total_loss, evade_mal_total_loss)) / total, metrics\n",
    "\n",
    "    def process_adv_examples(evade_method='dfgsm_k', mode='gen'):\n",
    "        \"\"\"\n",
    "        This function is used for the `attack` track challenge for two purposes\n",
    "        With mode='gen', it is meant to craft transferable adversarial examples and store them to a numpy array\n",
    "        With mode='eval', it loads up the examples from the numpy array and evaluates them on the tested model\n",
    "        Note, ADV Examples are only crafted for malicious files\n",
    "        :param evade_method: evasion method (participants can implement their own), here we use `dfgsm_k` as an example\n",
    "        :param mode: 'gen' to generate and store the adv examples or 'eval' to load them and evaluate\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        category = \"malicious\"\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        adv_file = os.path.join(adv_example_filepath, 'aes.npy')\n",
    "        xs_adv = [] if mode == 'gen' else np.load(adv_file)\n",
    "        # to be inline with the code base, the attack dataset will also be\n",
    "        # decomposed into train, val, and test. However, all these subsets will be\n",
    "        # used as part of the attack challenge.\n",
    "        xs_adv_offset = 0\n",
    "        for dset_type in ['train', 'val', 'test']:\n",
    "            if dset_type == 'train':\n",
    "                dataloader = train_dataloader_dict[category]\n",
    "            elif dset_type == 'val':\n",
    "                dataloader = valid_dataloader_dict[category]\n",
    "            elif dset_type == 'test':\n",
    "                dataloader = test_dataloader_dict[category]\n",
    "\n",
    "            # to impose the order of the crafted examples, we manually loop over the dataset\n",
    "            # instead of using the dataloader' sampler\n",
    "            batch_size = dataloader.batch_size\n",
    "            num_pts = len(dataloader.dataset)\n",
    "            num_batches = (num_pts + batch_size - 1) // batch_size\n",
    "\n",
    "            for batch_idx in range(num_batches):\n",
    "                # get the batch data\n",
    "                bstart = batch_idx * batch_size\n",
    "                bend = min(num_pts, bstart + batch_size)\n",
    "                x, y = zip(*[dataloader.dataset[i] for i in range(bstart, bend)])\n",
    "                x = torch.stack(x, dim=0)\n",
    "                y = torch.LongTensor(y)\n",
    "\n",
    "                if mode == 'gen':\n",
    "                    # put your method here\n",
    "                    # ---------------------------\n",
    "                    x_adv = inner_maximizer(\n",
    "                            x, y, model, loss_fct, iterations=evasion_iterations, method=evade_method)\n",
    "                    # ---------------------------\n",
    "\n",
    "                else:\n",
    "                    x_adv = torch.from_numpy(\n",
    "                        xs_adv[xs_adv_offset + batch_idx * batch_size:\n",
    "                               xs_adv_offset + (batch_idx + 1) * batch_size, :])\n",
    "\n",
    "                # stack input\n",
    "                if is_cuda:\n",
    "                    x_adv = Variable(x_adv.cuda())\n",
    "                    y = Variable(y.cuda())\n",
    "                else:\n",
    "                    x_adv = Variable(x_adv)\n",
    "                    y = Variable(y)\n",
    "\n",
    "                # forward pass\n",
    "                y_model = model(x_adv)\n",
    "\n",
    "                # loss pass\n",
    "                loss = loss_fct(y_model, y).mean()\n",
    "\n",
    "                # predict pass\n",
    "                _, predicted = torch.topk(y_model, k=1)\n",
    "                correct = predicted.data.eq(y.data.view_as(predicted.data)).cpu().sum()\n",
    "\n",
    "                # metrics\n",
    "                total_loss += loss.data[0] * len(y)\n",
    "                total_correct += correct\n",
    "                total += len(y)\n",
    "\n",
    "                # let's save the adversarial examples\n",
    "                _x = x.numpy()\n",
    "                _x_adv = x_adv.cpu().data.numpy() if is_cuda else x_adv.data.numpy()\n",
    "                assert np.allclose(np.logical_and(_x, _x_adv), _x), \"perturbation constraint violated\"\n",
    "                if mode == 'gen':\n",
    "                    xs_adv = xs_adv + [_x_adv]\n",
    "\n",
    "            xs_adv_offset += num_pts\n",
    "\n",
    "        if mode == 'gen':\n",
    "            np.save(adv_file, np.concatenate(xs_adv, axis=0))\n",
    "\n",
    "        # we keep the same structure of metrics for compatibility\n",
    "        metrics = {\n",
    "            \"bscn_num_pts\": 1,\n",
    "            \"bscn_exp_pts\": 1,\n",
    "            \"mal\": {\n",
    "                \"total_loss\": 1,\n",
    "                \"total_correct\": 1,\n",
    "                \"total\": 1,\n",
    "                \"evasion\": {\n",
    "                    \"total_loss\": total_loss,\n",
    "                    \"total_correct\": total_correct,\n",
    "                    \"total\": total\n",
    "                }\n",
    "            },\n",
    "            \"bon\": {\n",
    "                \"total_loss\": 1,\n",
    "                \"total_correct\": 1,\n",
    "                \"total\": 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    if not os.path.exists(\"result_files\"):\n",
    "        os.mkdir(\"result_files\")\n",
    "    _metrics = None\n",
    "\n",
    "    # Starter kit for Defend Challenge\n",
    "    if not eval(parameters[\"challenge\"][\"eval\"]) and eval(parameters[\"challenge\"][\"defend\"]):\n",
    "        best_valid_loss = float(\"inf\")\n",
    "        for _epoch in range(num_epochs):\n",
    "            # train\n",
    "            train(_epoch)\n",
    "            # validate\n",
    "            valid_loss, _ = test(_epoch, dset_type='val')\n",
    "            # keep the best parameters w.r.t validation and check the test set\n",
    "            if best_valid_loss > valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                _, _metrics = test(_epoch, dset_type='test')\n",
    "                bscn_to_save = bscn.ratio()\n",
    "                with open(os.path.join(\"result_files\", \"%s_bscn.txt\" % experiment_name), \"w\") as f:\n",
    "                    f.write(str(bscn_to_save))\n",
    "                torch.save(model, os.path.join(\"helper_files\", \"%s-model.pt\" % experiment_name))\n",
    "            elif _epoch % log_interval == 0:\n",
    "                test(_epoch, dset_type='test')\n",
    "\n",
    "    # starter kit for Attack challenge:\n",
    "    # participants can modify the code highlighted in the `process_adv_examples` function\n",
    "    if not eval(parameters[\"challenge\"][\"eval\"]) and eval(parameters[\"challenge\"][\"attack\"]):\n",
    "        _metrics = process_adv_examples(evade_method=evasion_method, mode='gen')\n",
    "\n",
    "    # Code for submission evaluations (this code will be run by the organizers),\n",
    "    # we are relasing it here for transparency\n",
    "    # for evaluating submissions under the Attack track\n",
    "    if eval(parameters[\"challenge\"][\"eval\"]) and eval(parameters[\"challenge\"][\"attack\"]):\n",
    "        _metrics = process_adv_examples(evade_method=evasion_method, mode='eval')\n",
    "\n",
    "    # for evaluating submissions under the Defend track\n",
    "    # For compatibility with the code above, our hold-out dataset will also\n",
    "    # be splitted into test, validation, and train. This is why we evaluate them all below.\n",
    "    if eval(parameters[\"challenge\"][\"eval\"]) and eval(parameters[\"challenge\"][\"defend\"]):\n",
    "        # report results on all datasets\n",
    "        _, _metrics = test(0, dset_type='test')\n",
    "        _, _metrics_t = test(0, dset_type='train')\n",
    "        _, _metrics_v = test(0, dset_type='val')\n",
    "        _metrics = merge_metrics([_metrics_t, _metrics, _metrics_v])\n",
    "\n",
    "    with open(os.path.join(\"result_files\", experiment_name + \".json\"), \"w\") as result_file:\n",
    "        json.dump(_metrics, result_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    end = time.time()\n",
    "    print(\"run time: %.3f\"%(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
